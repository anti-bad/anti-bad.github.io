---
layout: default
---

## About Anti-BAD Challenge

The **Anti-BAD: Anti-Adversarial Post-Training Backdoor Defense Challenge for Large Language Models** is a competition designed to address the growing security concerns in the era of widespread LLM deployment.

### Background

As obtaining and deploying language models from public hubs like HuggingFace becomes common practice, the risk of backdoor attacks increases. Malicious attackers can inject backdoors into models through fine-tuning on poisoned datasets or model editing, then publish these compromised models. The lack of transparency and model verification in current practices raises significant security concerns.

### Our Mission

This challenge focuses on practical constraints faced by end-users in realistic deployment scenarios. Unlike existing defenses that require large-scale data and compute resources, Anti-BAD encourages the development of lightweight, generalizable strategies for securing LLMs under constrained post-training settings with minimal data and training assumptions.

The competition is designed to foster constrained post-training settings with minimal data and training assumptions. It encourages defenses—whether adapting traditional methods or introducing novel ones—to evaluate their effectiveness under a fair benchmark. To broaden its impact, the challenge spans widely used LLM scenarios, including generation, classification, and multilingual tasks.

### Contact

For questions and inquiries, please contact us at: [antibad2025@gmail.com](mailto:antibad2025@gmail.com)